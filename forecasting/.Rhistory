mprice <- data_causal[, 3]
# Plot of the data
plot.ts(qty)
plot.ts(rprice)
plot.ts(mprice)
VARselect(data_causal, lag.max = 10, type="const")
var_model <- VAR(data_causal, p=1, type="const")
# Extract the residuals from the VAR model
qty_res <- var_model$varresult$Move$residuals
rprice_res <- var_model$varresult$RPRICE$residuals
mprice_res <- var_model$varresult$MPRICE$residuals
# Check for stationarity using the Augmented Dickey-Fuller test
qty_lag <- ndiffs(qty_res)
mprice_lag <- ndiffs(mprice_res)
rprice_lag <- ndiffs(rprice_res)
# Augmented Dickey-Fuller test
# used urca library as it gives more precise results of the test than the adf.test
qty_adf <- ur.df(qty_res, lags = qty_lag, type="none")
mprice_adf <- ur.df(mprice_res, lags = mprice_lag, type="none")
rprice_adf <- ur.df(rprice_res, lags = rprice_lag, type="none")
summary(qty_adf)
summary(mprice_adf)
summary(rprice_adf)
# Check whether the variables follow a Gaussian distribution
ks.test(qty_res,"pnorm", mean = mean(qty_res), sd = sd(qty_res))
ks.test(mprice_res,"pnorm", mean = mean(mprice_res), sd = sd(mprice_res))
ks.test(rprice_res,"pnorm", mean = mean(rprice_res), sd = sd(rprice_res))
# Write the residuals to a csv file to build causal graphs using Tetrad software
residual_data <- cbind(qty_res, rprice_res, mprice_res)
write.csv(residual_data, file = tetrd_file_path, row.names = FALSE)
# PC Algorithm
suffStat =  list(C=cor(residual_data), n = nrow(residual_data))
pc_algo_res <- pc(suffStat, indepTest = gaussCItest, alpha = 0.1, labels = colnames(residual_data), skel.method = "original")
plot(pc_algo_res, main="PC Algorithm Output")
# LinGam Algorithm
lingam_algo_res <- lingam(residual_data)
plot(lingam_algo_res)
show(lingam_algo_res)
# This project is created by:
# Name: Aditya Bhardwaj
# Unity ID: abhardw2
# Project Title: Project 7 - Causal Discovery between Manufacturer-Retailer Price Channels
# Load the libraries
library(vars)
library(urca)
library(pcalg)
library(stats)
library(lmtest)
library(forecast)
library(tseries)
# Read the input data
csv_file_path <- "BI/Projects/Project7/Input Data/data.csv"
tetrd_file_path <- "BI/Projects/Project7/Input Data/tetrd.csv"
data_causal <- read.csv(csv_file_path, sep = ",", header = TRUE)
ts_causal <- ts(data_causal, frequency = 52)
# Build a VAR model
qty <- data_causal[, 1]
rprice <- data_causal[, 2]
mprice <- data_causal[, 3]
# Plot of the data
plot.ts(qty)
plot.ts(rprice)
plot.ts(mprice)
VARselect(data_causal, lag.max = 10, type="const")
var_model <- VAR(data_causal, p=1, type="const")
# Extract the residuals from the VAR model
qty_res <- var_model$varresult$Move$residuals
rprice_res <- var_model$varresult$RPRICE$residuals
mprice_res <- var_model$varresult$MPRICE$residuals
# Check for stationarity using the Augmented Dickey-Fuller test
qty_lag <- ndiffs(qty_res)
mprice_lag <- ndiffs(mprice_res)
rprice_lag <- ndiffs(rprice_res)
# Augmented Dickey-Fuller test
# used urca library as it gives more precise results of the test than the adf.test
qty_adf <- ur.df(qty_res, lags = qty_lag, type="none")
mprice_adf <- ur.df(mprice_res, lags = mprice_lag, type="none")
rprice_adf <- ur.df(rprice_res, lags = rprice_lag, type="none")
summary(qty_adf)
summary(mprice_adf)
summary(rprice_adf)
# Check whether the variables follow a Gaussian distribution
ks.test(qty_res,"pnorm", mean = mean(qty_res), sd = sd(qty_res))
ks.test(mprice_res,"pnorm", mean = mean(mprice_res), sd = sd(mprice_res))
ks.test(rprice_res,"pnorm", mean = mean(rprice_res), sd = sd(rprice_res))
# Write the residuals to a csv file to build causal graphs using Tetrad software
residual_data <- cbind(qty_res, rprice_res, mprice_res)
write.csv(residual_data, file = tetrd_file_path, row.names = FALSE)
# PC Algorithm
suffStat =  list(C=cor(residual_data), n = nrow(residual_data))
pc_algo_res <- pc(suffStat, indepTest = gaussCItest, alpha = 0.1, labels = colnames(residual_data), skel.method = "original")
plot(pc_algo_res, main="PC Algorithm Output")
# LinGam Algorithm
lingam_algo_res <- lingam(residual_data)
show(lingam_algo_res)
plot.ts(qty)
plot.ts(rprice)
plot.ts(mprice)
summary(qty_adf)
summary(mprice_adf)
summary(rprice_adf)
plot(pc_algo_res, main="PC Algorithm Output")
show(lingam_algo_res)
lingam_algo_res <- lingam(residual_data, verbose = TRUE)
show(lingam_algo_res)
plot(lingam_algo_res)
plot(lingam_algo_res, main="LinGam Algorithm Output")
as(lingam_algo_res, "amat")
plotling <- as(lingam_algo_res, "amat")
plot(plotling)
plot(plotling)
library(XBRL)
library(devtools)
xbrl_url2014 <- "https://www.sec.gov/Archives/edgar/data/320193/000119312514383437/aapl-20140927.xml"
mmdf <- "https://www.sec.gov/Archives/edgar/data/1318605/000156459017003118/tsla-20161231.xml"
old_o <- options(stringsAsFactors = FALSE)
xbrl_data_aapl2014 <- xbrlDoAll(mmdf)
library(XBRL)
library(devtools)
xbrl_url2014 <- "https://www.sec.gov/Archives/edgar/data/320193/000119312514383437/aapl-20140927.xml"
mmdf <- "https://www.sec.gov/Archives/edgar/data/1318605/000156459017003118/tsla-20161231.xml"
asd <-  "https://www.sec.gov/Archives/edgar/data/1318605/000156459017003118/tsla-20161231.xsd"
old_o <- options(stringsAsFactors = FALSE)
xbrl_data_aapl2014 <- xbrlDoAll(asd)
xbrl_data_aapl2014 <- xbrlDoAll(xbrl_url2014)
xbrl_data_aapl2014 <- xbrlDoAll(asd)
options(old_o)
library(finstr)
st2013 <- xbrl_get_statements(xbrl_data_aapl2014)
st2013
balance_sheet2013 <- st2013$StatementOfFinancialPositionClassified
balance_sheet2013
income2013 <- st2013$StatementOfIncome
income2013
check <- check_statement(balance_sheet2014)
check <- check_statement(balance_sheet2013)
check
library(XBRL)
library(finstr)
xbrl_url2014 <- "https://www.sec.gov/Archives/edgar/data/320193/000119312514383437/aapl-20140927.xml"
xbrl_url2016 <-  "https://www.sec.gov/Archives/edgar/data/1318605/000156459017003118/tsla-20161231.xsd"
old_o <- options(stringsAsFactors = FALSE)
xbrl_data_tesla2016 <- xbrlDoAll(xbrl_url2016)
options(old_o)
st2016 <- xbrl_get_statements(xbrl_data_tesla2016)
xbrl_data_tesla2016 <- xbrlDoAll(xbrl_url2016)
xbrl_data_aapl2014 <- xbrlDoAll(xbrl_url2014)
st2014 <- xbrl_get_statements(xbrl_data_aapl2014)
balance_sheet2014 <- st2014$StatementOfFinancialPositionClassified
income2014 <- st2014$StatementOfIncome
check <- check_statement(balance_sheet2014)
st2014
balance_sheet2014
income2014
income2014$NetIncomeLoss
4.1733e+10
income2014$GrossProfit
gm_url2016 <- "https://www.sec.gov/Archives/edgar/data/1467858/000146785817000028/gm-20161231.xsd"
old_o <- options(stringsAsFactors = FALSE)
xbrl_data_tesla2016 <- xbrlDoAll(xbrl_url2016)
data_gm2016 <- xbrlDoAll(gm_url2016)
gm_url2016 <- "https://www.sec.gov/Archives/edgar/data/1467858/000146785817000028/gm-20161231.xml"
old_o <- options(stringsAsFactors = FALSE)
xbrl_data_tesla2016 <- xbrlDoAll(xbrl_url2016)
data_gm2016 <- xbrlDoAll(gm_url2016)
options(old_o)
st_gm_2016 <- xbrl_get_statements(data_gm2016)
xbrl_data_aapl2014 <- xbrlDoAll(xbrl_url2014)
st2014 <- xbrl_get_statements(xbrl_data_aapl2014)
balance_sheet2014 <- st2014$StatementOfFinancialPositionClassified
income2014 <- st2014$StatementOfIncome
check <- check_statement(balance_sheet2014)
gm_url2016 <- "https://www.sec.gov/Archives/edgar/data/1467858/000146785817000028/gm-20161231.xml"
old_o <- options(stringsAsFactors = FALSE)
xbrl_data_tesla2016 <- xbrlDoAll(xbrl_url2016)
data_gm2016 <- xbrlDoAll(gm_url2016)
options(old_o)
st_gm_2016 <- xbrl_get_statements(data_gm2016)
xbrl_data_gm2016 <- xbrlDoAll(gm_url2016)
xbrl_url2014 <- "https://www.sec.gov/Archives/edgar/data/320193/000119312514383437/aapl-20140927.xsd"
xbrl_data_aapl2014 <- xbrlDoAll(xbrl_url2014)
st2014 <- xbrl_get_statements(xbrl_data_aapl2014)
balance_sheet2014 <- st2014$StatementOfFinancialPositionClassified
income2014 <- st2014$StatementOfIncome
check <- check_statement(balance_sheet2014)
st2014
xbrl_data_gm2016 <- xbrlDoAll(gm_url2016)
st_gm_2016 <- xbrl_get_statements(xbrl_data_gm2016)
library(XBRL)
library(finstr)
xbrl_url2016 <-  "https://www.sec.gov/Archives/edgar/data/1318605/000156459017003118/tsla-20161231.xml"
old_o <- options(stringsAsFactors = FALSE)
xbrl_data_tesla2016 <- xbrlDoAll(xbrl_url2016)
xbrl_data_gm2016 <- xbrlDoAll(gm_url2016)
options(old_o)
xbrl_url2014 <- "https://www.sec.gov/Archives/edgar/data/320193/000119312514383437/aapl-20140927.xml"
xbrl_data_aapl2014 <- xbrlDoAll(xbrl_url2014)
st2014 <- xbrl_get_statements(xbrl_data_aapl2014)
balance_sheet2014 <- st2014$StatementOfFinancialPositionClassified
income2014 <- st2014$StatementOfIncome
check <- check_statement(balance_sheet2014)
check
income2014$NetIncomeLoss
income2014$GrossProfit
income2014$IncomeTaxExpenseBenefit
xbrl_url2016 <-  "https://www.sec.gov/Archives/edgar/data/1318605/000156459017003118/tsla-20161231.xml"
xbrl_data_aapl2014 <- xbrlDoAll(xbrl_url2016)
xbrl_url2016 <-  "https://www.sec.gov/Archives/edgar/data/1318605/000156459017003118/tsla-20161231.xsd"
xbrl_data_aapl2014 <- xbrlDoAll(xbrl_url2016)
library(‘quantmod’)
install.packages('quantmod')
quantmod’
library(quantmod)
getSymbols(“AAPL”)
?getSymbols
getSymbols('AAPL)
chartSeries(AAPL, subset=’last 3 months’)
addBBands()
AAPL[‘2010-06-01::2010-06-26’]
head(as.xts(merge(ORCL,IBM)))
sdfd
.
/
`;
sd
fsdsd
''
/\
'_
getSymbols('AAPL')
chartSeries(AAPL, subset=’last 3 months’)
chartSeries(AAPL, subset='last 3 months')
addBBands()
AAPL[‘2010-06-01::2010-06-26’]
head(as.xts(merge(ORCL,IBM)))
getSymbols(c('ORCL','IBM'))
head(as.xts(merge(ORCL,IBM)))
chartSeries(ORCL~IBM, subset='last 3 months')
chartSeries(ORCL,IBM, subset='last 3 months')
chartSeries(ORCL, subset='last 3 months')
addBBands()
getSymbols('TSLA')
chartSeries(TSLA, subset='last 3 months')
addBBands()
library(XBRL)
library(finstr)
xbrl_aapl_url2014 <- "https://www.sec.gov/Archives/edgar/data/320193/000119312514383437/aapl-20140927.xml"
xbrl_tsla_url2016 <-  "https://www.sec.gov/Archives/edgar/data/1318605/000156459017003118/tsla-20161231.xml"
gm_url2016 <- "https://www.sec.gov/Archives/edgar/data/1467858/000146785817000028/gm-20161231.xsd"
old_o <- options(stringsAsFactors = FALSE)
xbrl_data_tesla2016 <- xbrlDoAll(xbrl_tsla_url2016)
xbrl_aapl_url2014 <- "https://www.sec.gov/Archives/edgar/data/320193/000119312514383437/aapl-20140927.xml"
xbrl_data_tesla2016 <- xbrlDoAll(xbrl_aapl_url2016)
xbrl_data_tesla2016 <- xbrlDoAll(xbrl_aapl_url2014)
xbrl_aapl_url2014 <- "https://www.sec.gov/Archives/edgar/data/320193/000119312514383437/aapl-20140927.xml"
xbrl_tsla_url2016 <-  "https://www.sec.gov/Archives/edgar/data/1318605/000156459017003118/tsla-20161231.xml"
gm_url2016 <- "https://www.sec.gov/Archives/edgar/data/1467858/000146785817000028/gm-20161231.xsd"
old_o <- options(stringsAsFactors = FALSE)
xbrl_data_tesla2016 <- xbrlDoAll(xbrl_aapl_url2014)
library(XBRL)
library(finstr)
xbrl_aaplurl2014 <- "https://www.sec.gov/Archives/edgar/data/320193/000119312514383437/aapl-20140927.xml"
old_o <- options(stringsAsFactors = FALSE)
xbrl_data_tesla2016 <- xbrlDoAll(xbrl_aaplurl2014)
install.packages('edgar')
library(edgar)
getFilingInfo('TSLA', 2015)
daily.filing.info <- getDailyMaster('08/09/2016')
daily.filing.info
info <- getFilingInfo('United Technologies', 1994)
report <- getFilings(1994, 100030, 'ALL')
library(XBRL)
library(finstr)
xbrl_aaplurl2014 <- "https://www.sec.gov/Archives/edgar/data/320193/000119312514383437/aapl-20140927.xml"
xbrl_tsla_url2016 <-  "https://www.sec.gov/Archives/edgar/data/1318605/000156459017003118/tsla-20161231.xml"
gm_url2016 <- "https://www.sec.gov/Archives/edgar/data/1467858/000146785817000028/gm-20161231.xsd"
old_o <- options(stringsAsFactors = FALSE)
xbrl_data_tesla2016 <- xbrlDoAll(xbrl_aaplurl2014)
xbrl_data_gm2016 <- xbrlDoAll(gm_url2016)
options(old_o)
st2016 <- xbrl_get_statements(xbrl_data_tesla2016)
balance_sheet2016 <- st2016$StatementOfFinancialPositionClassified
income2016 <- st2016$StatementOfIncome
check <- check_statement(balance_sheet2016)
st_gm_2016 <- xbrl_get_statements(xbrl_data_gm2016)
xbrl_data_aapl2014 <- xbrlDoAll(xbrl_url2014)
xbrl_data_aapl2014 <- xbrlDoAll(xbrl_url2016)
st2014 <- xbrl_get_statements(xbrl_data_aapl2014)
balance_sheet2014 <- st2014$StatementOfFinancialPositionClassified
income2014 <- st2014$StatementOfIncome
install.packages("finreportr")
devtools::install_github("sewardlee337/finreportr")
CompanyInfo("GOOG")
library(finreportr)
CompanyInfo("GOOG")
AnnualReports("GOOG", foreign = FALSE)
GetIncome("TSLA", 2014)
GetIncome("GOOG", 2014)
head(GetIncome("GOOG", 2016), 20)
head(GetBalanceSheet("GOOG", 2016), 20)
getOption("download.file.method")
head(GetIncome("GOOG", 2016))
options(download.file.method = "internal")
head(GetIncome("GOOG", 2016))
options(download.file.method = "auto")
head(GetIncome("GOOG", 2016))
options(download.file.method = "curl")
head(GetIncome("GOOG", 2016))
head(GetBalanceSheet("GOOG", 2016), 20)
balanceSheet <- GetBalanceSheet("GOOG", 2016)
balanceSheet
balanceSheet$Amount
head(balanceSheet)
head(balanceSheet, 20)
balanceSheet <- head(GetBalanceSheet("GOOG", 2016), 20)
AnnualReports("GOOG")
GetIncome("GOOG", 20016)
GetIncome("GOOG", 2016)
cashFlow <- GetCashFlow("TSLA", 2016)
cashFlow
cashFlow$Metric
s <- 0
if ( cashFlow$Metric == "Net Income Loss"){
s = s + cashFlow$Amount
}
typeof(cashFlow$Amount[1])
s <- 0
if ( cashFlow$Metric == "Net Income Loss"){
s = s + as.integer(cashFlow$Amount)
}
s
cashFlow$Metric
library(XBRL)
library(finstr)
library(quantmod)
getSymbols("HMC")
getSymbols("DJIA",src="FRED")
getFinancials("DJIA")
getFinancials(DJIA.A)
getFinancials(DJIA.TS)
getFinancials(DJIA.T)
getFinancials(DJIA.S)
JAVA <- getFinancials('JAVA')
download.file(paste(google.fin, 'JAVA', sep=""))
download.file(paste(google.fin, 'JAVA', sep=""), 'asdad')
?download.file
download.file(http://finance.google.com/finance?fstype=ii&q=JAVA, 'asdad')
download.file("http://finance.google.com/finance?fstype=ii&q=JAVA", 'asdad')
download.file(url = "http://finance.google.com/finance?fstype=ii&q=JAVA", destfile = 'asdad', method = 'curl')
library("finreportr", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
options(download.file.method = "curl")
g <- head(GetIncome("TSLA", 2017), 20)
g <- GetIncome("TSLA", 2016)
CompanyInfo("GOOG")
CompanyInfo("GOOG")
CompanyInfo("CPST")
CompanyInfo("ZAAP")
CompanyInfo("TM")
CompanyInfo("UQM")
CompanyInfo("KNDI")
CompanyInfo("PPO")
CompanyInfo("F")
CompanyInfo("PLUG")
CompanyInfo("JCI")
CompanyInfo("DAI")
CompanyInfo("MGA")
CompanyInfo("AONE")
CompanyInfo("ABAT")
CompanyInfo("ALTI")
CompanyInfo("CBAK")
CompanyInfo("SQM")
CompanyInfo("HEV")
CompanyInfo("QTWW")
CompanyInfo("VLNC")
CompanyInfo("CCG")
CompanyInfo("CCGI")
CompanyInfo("EVSI")
CompanyInfo("AVAV")
AnnualReports("AVAV")
cashFlow
View(AAPL)
AAPL
AAPL.Open
AAPL$AAPL.Open
min(AAPL$AAPL.LOW)
min(AAPL$AAPL.Low)
max(AAPL$AAPL.High)
View(DJIA)
library(XBRL)
library(finstr)
library(quantmod)
library(fma)
library(Quandl)
library(finreportr)
options(download.file.method = "curl")
GetIncome("TSLA", 2017)
GetIncome("AAPL", 2017)
options(download.file.method = "wget")
GetIncome("AAPL", 2017)
options(download.file.method = "internal")
GetIncome("AAPL", 2017)
options(download.file.method = "auto")
GetIncome("AAPL", 2017)
library(quantmod)
getFX(c("gold","XPD"))
getMetals(c('gold'))
getSymbols("GOLD/USD",src="Oanda")
XPT
getSymbols("XPT/USD",src="Oanda")
getMetals(Metals = 'gold', base.currency = 'USD', from = '2013-10-10')
getMetals(Metals = 'gold', base.currency = 'USD')
getMetals(Metals = 'gold', base.currency = 'USD', from = as.Date('2013-10-10'))
require(forecast)
require(hydroGOF)
require(smooth)
require(Mcomp)
require(TTR)
setwd("/Users/ADITYA/data/NCState/iot/project/forecasting/")
dataset <- read.csv('BHARDWAJ ADITYA_1.csv', header = TRUE)
dataset <- ts(dataset)
trainSize <- floor(nrow(dataset) * 0.75)
testSize <- nrow(dataset) - trainSize
trainData <- ts(dataset[1:trainSize], start = 1, end = trainSize)
testData <- ts(dataset[(trainSize + 1):length(dataset)], start = trainSize + 1, end = length(dataset))
predictedData <- sma(trainData, 3)
predictedData <- fitted(predictedData)
calculatedRmse <- rmse(trainData, predictedData)
plot.ts(trainData, col = 'blue', ylab = "Values", main = paste("Training Data vs Fitted Data for Simple Moving Average Model at M =", 3, sep = " "))
lines(predictedData, col='red')
legend("topright",legend=c("Training Data", "Fitted Values"),lty=1:1, cex=0.8, box.lty=0, horiz=TRUE,col=c("blue","red"))
n <- 100
mat.ma <- matrix(ncol=2, nrow=n)
for (m in 1:100){
predictedData <- sma(trainData, m)
predictedData <- fitted(predictedData)
calculatedRmse <- rmse(trainData, predictedData)
mat.ma[m,] <- c(m, calculatedRmse)
}
plot(mat.ma, type = 'o', col = "lightblue", main= "RMSE values for Simple Moving Average", xlab = 'm', ylab = "RMSE")
sma.predictedData <- sma(trainData, 2)
sma.predictedData <- fitted(sma.predictedData)
plot.ts(trainData, col = 'blue', ylab = "Values", main = paste("Training Data vs Fitted Data for Simple Moving Average Model at M =", 2, sep = " "))
lines(sma.predictedData, col='red')
legend("topright",legend=c("Training Data", "Fitted Values"),lty=1:1, cex=0.8, box.lty=0, horiz=TRUE,col=c("blue","red"))
ema.fun <- function(trainData, alpha) {
fittedVector <- c()
fittedVector <- c(fittedVector, trainData[1])
for( i in 2:length(trainData)){
expSmooth <- alpha * trainData[i-1] + (1-alpha) * fittedVector[i-1]
fittedVector <- c(fittedVector, expSmooth)
}
returnTS <- ts(fittedVector)
return(returnTS)
}
predictedData <- ema.fun(trainData, 0.45)
rmse.ema.predictedData <- rmse(trainData, predictedData)
print(paste(paste("RMSE value for Exponential Smoothing Model at alpha=", 0.45, sep = " "), rmse.ema.predictedData, sep = " : " ))
plot.ts(trainData, col = 'blue', ylab = "Values", main = paste("Training Data vs Fitted Data for Exponential Smoothing Model at Alpha =", 0.45, sep = " "))
lines(predictedData, col='red')
legend("topright",legend=c("Training Data", "Fitted Values"),lty=1:1, cex=0.8, box.lty=0, horiz=TRUE,col=c("blue","red"))
n <- 100
mat.ema <- matrix(ncol=2, nrow=n)
for (m in 1:100) {
nm <- m/100
predictedData <- ema.fun(trainData, nm)
calculatedRmse <- rmse(trainData, predictedData)
mat.ema[m,] <- c(m, calculatedRmse)
}
plot(mat.ema, type = 'o', col = "lightblue", main= "RMSE values for Exponential Smoothing Model", xlab = 'm', ylab = "RMSE")
ema.predictedData <- ema.fun(trainData, 0.62)
plot.ts(trainData, col = 'blue', ylab = "Values", main = paste("Training Data vs Fitted Data for Exponential Smoothing Model at Alpha =", 0.62, sep = " "))
lines(ema.predictedData, col='red')
legend("topright",legend=c("Training Data", "Fitted Values"),lty=1:1, cex=0.7, box.lty=0, horiz=TRUE,col=c("blue","red"))
pacf(trainData)
p <- 2
ar.mod <- auto.arima(trainData, d = 0, max.q = 0, max.p = 5)
fit.ar <- fitted(ar.mod)
rmse.ar <- rmse(trainData, fit.ar)
print(paste(paste("RMSE value for AR(p) model at p =", 5, sep = " "), rmse.ar, sep = " : " ))
plot.ts(trainData, col = 'blue', ylab = "Values", main = paste("Training Data vs Fitted Data for AR(p) Model at P =", 5, sep = " "))
lines(fit.ar, col='red')
legend("topright",legend=c("Training Data", "Fitted Values"),lty=1:1, cex=0.8, box.lty=0, horiz=TRUE,col=c("blue","red"))
ar.mod <- auto.arima(trainData, d = 0, max.q = 0, max.p = p)
fit.ar <- fitted(ar.mod)
rmse.ar <- rmse(trainData, fit.ar)
print(paste(paste("RMSE value for AR(p) model at p =", p, sep = " "), rmse.ar, sep = " : " ))
plot.ts(trainData, col = 'blue', ylab = "Values", main = paste("Training Data vs Fitted Data for AR(p) Model at P =", 2, sep = " "))
lines(fit.ar, col='red')
legend("topright",legend=c("Training Data", "Fitted Values"),lty=1:1, cex=0.8, box.lty=0, horiz=TRUE,col=c("blue","red"))
comparisonMat <- matrix(ncol=2, nrow=3)
sma.predictedTestData <- sma(testData, 2)
sma.predictedTestData <- fitted(sma.predictedTestData)
fit.sma.predictedTestData <- ts(sma.predictedTestData, start = trainSize + 1,end = length(dataset))
comparisonMat[1,] <- c("Simple Moving Average",rmse(testData, fit.sma.predictedTestData))
plot.ts(testData, col = 'blue', ylab = "Values", main = paste("Testing Data vs Fitted Data for Simple Moving Average Model at M =", 2, sep = " "))
lines(fit.sma.predictedTestData, col='red')
legend("topright",legend=c("Testing Data", "Fitted Values"), lty=1:1, cex=0.7, box.lty=0, horiz=TRUE,col=c("blue","red"))
ema.predictedTestData <- ema.fun(testData, 0.62)
fit.ema.predictedTestData <- ts(ema.predictedTestData, start = trainSize + 1,end = length(dataset))
comparisonMat[2,] <- c("Exponential Smoothing",rmse(testData, fit.ema.predictedTestData))
plot.ts(testData, col = 'blue', ylab = "Values", main = paste("Testing Data vs Fitted Data for Exponential Smoothing Model at Alpha =", 0.62, sep = " "))
lines(fit.ema.predictedTestData, col='red')
legend("topright",legend=c("Testing Data", "Fitted Values"), lty=1:1, cex=0.7, box.lty=0, horiz=TRUE, col=c("blue","red"))
ar.mod <- auto.arima(testData, d = 0, max.q = 0, max.p = p)
fit.ar.predictedTestData = fitted(ar.mod, start = trainSize + 1,end = length(dataset))
comparisonMat[3,] <- c("AR(p) Model",rmse(testData, fit.ar.predictedTestData))
print(paste(paste("RMSE value for AR(p) model at p =", p, sep = " "), comparisonMat[3,2], sep = " : " ))
plot.ts(testData, col = 'blue', ylab = "Values", main = paste("Training Data vs Fitted Data for AR(p) Model at P =", 2, sep = " "))
lines(fit.ar.predictedTestData, col='red')
legend("topright",legend=c("Training Data", "Fitted Values"), lty=1:1, cex=0.7, box.lty=0, horiz=TRUE,col=c("blue","red"))
plot(y = comparisonMat[,2], x = 1:3, xlab = "Models", ylab = "RMSE", xaxt = 'n', main = "RMSE Comparison for three models", type = 'o')
axis(1, at = seq(1, 3, by = 1),labels = comparisonMat[,1], las = 1)
